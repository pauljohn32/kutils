%% LyX 2.2.0 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english,american,noae]{scrartcl}
\usepackage{lmodern}
\renewcommand{\sfdefault}{lmss}
\renewcommand{\ttdefault}{lmtt}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\usepackage{float}
\usepackage[authoryear]{natbib}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
<<echo=F>>=
  if(exists(".orig.enc")) options(encoding = .orig.enc)
@
\newcommand{\code}[1]{\texttt{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
%\VignetteIndexEntry{variablekey}

\usepackage{booktabs}
\usepackage{Sweavel}
\usepackage{graphicx}
\usepackage{color}

\usepackage[samesize]{cancel}



\usepackage{ifthen}

\makeatletter

\renewenvironment{figure}[1][]{%

 \ifthenelse{\equal{#1}{}}{%

   \@float{figure}

 }{%

   \@float{figure}[#1]%

 }%

 \centering

}{%

 \end@float

}

\renewenvironment{table}[1][]{%

 \ifthenelse{\equal{#1}{}}{%

   \@float{table}

 }{%

   \@float{table}[#1]%

 }%

 \centering

%  \setlength{\@tempdima}{\abovecaptionskip}%

%  \setlength{\abovecaptionskip}{\belowcaptionskip}%

% \setlength{\belowcaptionskip}{\@tempdima}%

}{%

 \end@float

}


%\usepackage{listings}
% Make ordinary listings look as if they come from Sweave
\lstset{tabsize=2, breaklines=true, %,style=Rstyle}
                        fancyvrb=false,escapechar=`,language=R,%
                        %%basicstyle={\Rcolor\Sweavesize},%
                        backgroundcolor=\Rbackground,%
                        showstringspaces=false,%
                        keywordstyle=\Rcolor,%
                        commentstyle={\Rcommentcolor\ttfamily\itshape},%
                        literate={<<-}{{$\twoheadleftarrow$}}2{~}{{$\sim$}}1{<=}{{$\leq$}}2{>=}{{$\geq$}}2{^}{{$^{\scriptstyle\wedge}$}}1{==}{{=\,=}}1,%
                        alsoother={$},%
                        alsoletter={.<-},%
                        otherkeywords={!,!=,~,$,*,\&,\%/\%,\%*\%,\%\%,<-,<<-,/},%
                        escapeinside={(*}{*)}}%


% In document Latex options:
\fvset{listparameters={\setlength{\topsep}{0em}}}
\def\Sweavesize{\scriptsize} 
\def\Rcolor{\color{black}} 
\def\Rbackground{\color[gray]{0.95}}

% for sideways table
\usepackage{rotating}

\makeatother

\usepackage{babel}
\usepackage{listings}
\addto\captionsamerican{\renewcommand{\lstlistingname}{\inputencoding{latin9}Listing}}
\addto\captionsenglish{\renewcommand{\lstlistingname}{\inputencoding{latin9}Listing}}
\renewcommand{\lstlistingname}{\inputencoding{latin9}Listing}

\begin{document}

\title{The Variable Key Data Programming Framework}

\author{Paul E. Johnson and Benjamin A. Kite}
\maketitle
\begin{abstract}
This essay describes the ``variable key'' approach to importing
and recoding data. This method has been developed in the Center for
Research Methods and Data Analysis at the University of Kansas to
deal with the importation of large, complicated data sets. This approach
improves teamwork, keeps better records, and reduces slippage between
the intentions of principal investigators the implementation by code
writers. The framework is implemented in the R \citep{RCore} package
\code{kutils}. 
\end{abstract}
<<echo=F>>=
if(!dir.exists("plots")) dir.create("plots")
@

\selectlanguage{english}%
% In document Latex options:
\fvset{listparameters={\setlength{\topsep}{0em}}}
\SweaveOpts{prefix.string=plots/t,split=T,ae=F,height=4,width=5.5}

<<Roptions, echo=F>>=
options(device = pdf)
options(width=100, prompt=" ", continue="  ")
options(useFancyQuotes = FALSE) 
options(SweaveHooks=list(fig=function() par(ps=10)))
pdf.options(onefile=F,family="Times",pointsize=10)
@
\selectlanguage{american}%

\section{Introduction}

The staff of the Center for Research Methods and Data Analysis has
been asked to help with data importation and recoding from time to
time. In one very large project, we were asked to combine, recode,
and integrate variables from 21 different files. The various files
used different variable names and had different, unique coding schemes.
A skeptic might have thought that the firm which created the data
sets intentionally obfuscated the records to prevent the comparison
of variables across a series of surveys.

In projects like that, the challenge of importing and fixing the data
seems overwhelming. The graduate research assistants are asked to
cobble together thousands of lines of ``recodes'' as they rename,
regroup, and otherwise harmonize the information. From a managerial
point of view, that is not the main problem. We expect to spend the
time of research assistants. While it may be tedious to read a codebook
and write recodes, social scientists have been doing that since the
1960s. It is not all that difficult. The truly difficult part is mustering
up the confidence in the resulting recoded data. How can a supervisor
check thousands of recode statements for accuracy? The very extensibility
of R itself–its openness to new functions and language elements–makes
proof-reading more difficult. We might shift some of the proof reading
duty to the principle investigators, but they sometimes not interested
in details. In the end, the responsibility for verifying the recodes
falls on the project supervisors. While most supervisors with whom
we are personally acquainted have nearly super-human reading skills
and almost-perfect comprehension, we have documented a case in which
one of them was unable to catch an error on line 827 within an R file
with 2119 lines. 

To reduce the risk of misunderstanding and error, we propose the \emph{variable
key procedure}. It is a systematic way to separate code writing from
the process of renaming variables and re-designating their values.
The characteristics of the data are summarized in a table, a simple-looking
structure that might be edited in a text editor or a spread sheet
program. This simple structure, which we call the variable key, can
be used by principal investigators and supervisors to designate the
desired results. Once the key is created, then the data set can be
imported and recoded by the application of the key's information.
This does not eliminate the need to proof-read the renaming and recoding
of the variables, it simply shifts that chore into a simpler, more
workable setting.

This essay proceeds in 3 parts. First, the general concepts behind
the variable key system are explored. Second, the four stages in the
variable key procedure are outlined and illustrated with examples.
Third, we offer some examples of ways to double-check the results.

\section{Enter the Variable Key}

The variable key process was first developed for a very large project
for which we were hired by a commercial consulting company. As it
happened, the project manager who hired us was an Excel user who did
not know about R. He was given several SPSS datasets. After going
through the usual R process of importing and recoding data from 6
files, the aggregate of which included more than 40,000 observations
on 150 variables, we arrived at a renamed set of columns. Unfortunately,
the research assistant who had done most of the work resigned in order
to pursue a career as a magician.\footnote{Or graduated, we are not sure which.} 

With the unavailability of our key asset, it was difficult to know
for sure what was in which column. There was nobody to quickly answer
questions like ``which column is the respondent's sexual identity?''
and ``if sex is V23418, did we change 1 to male or female''. The
only way to find out is by hunting and pecking through a giant R file. 

In order to better communicate about that project, we developed a
table that looked like Table \ref{tab:A-Small-Variable-key}.

\begin{table}[H]
\caption{A Small Variable Key\label{tab:A-Small-Variable-key}}

\begin{tabular}{|c|c|c|c|}
\hline 
name\_old & name\_new & values\_old & values\_new\tabularnewline
\hline 
\hline 
V23419 & sex & 1|2|3 & ``male''|''female''|''neither''\tabularnewline
\hline 
V32422 & education & 1|2|3|4|5 & ``elem''<''hs''<''somecoll''<''ba''<''post''\tabularnewline
\hline 
V54532 & income & . & numeric\tabularnewline
\hline 
\end{tabular}
\end{table}

It was tedious to assemble that table, but it helped quite a bit in
our discussions. The vertical bars were used to indicate that the
original data had discrete values. When a variable has a natural ordering,
the new values were placed in order with the symbol (``<''). That
table grew quite large, since it had one row per variable, but it
was otherwise workable. It was popular with the client. 

In the middle of preparing that summary table of recoded values, we
realized that it was possible to write an R program to import the
key table and use its information to recode and rename the variables.
The recodes would \emph{just happen}. If we prepared the functions
properly, we had not just a table masquerading as a codebook, we had
a \emph{programmable codebook}. We wrote some functions that could
import variables (as named in column 1), apply the new values (from
columns 3 and 4), then apply the new name from column 2. The functions
to do that are, of course, somewhat difficult to prepare, but, from
a supervisor's point of view, they are very appealing. There will
be less proof-reading to do, at least in the R code itself. Once we
can validate the functions, then we never have proof-read them again.
These functions can be applied, row by row, to create a new data frame.
Instead, we need to concentrate our attention on the substance of
the problem, the specification of the new names and values in the
table.

In the projects where we have employed this system, we adjusted the
key and the R functions to suit the particular demands of the project
and the client. That was unfortunate, because we had very little accumulation
of code from one project to another. However, we did accumulate experience;
there were concepts and vocabulary which allowed us to understand
the various challenges that might be faced. The effort to develop
a standardized framework for the variable key began in 2016 with the
creation of the \code{kutils} package for R.

The variable key process allows project supervisors to create a table
that instructs the research assistants in the importation, renaming,
and recoding of data. There is still a daunting problem, however,
because the supervisors must create that variable key table. In a
large data set, it might be arduous to simply type the old names of
the variables and their observed values. In 2015 one of the graduate
assistants in our lab was asked to type up a variable key and he couldn't
quite believe that was a good use of his time. After some discussion,
we realized that it was not necessary to type the variable key at
all. We would write a function to do so. If R can import the candidate
data set, then R can certainly output its column names and a roster
of observed values. This lightened the workload considerably. By tabulating
all of the observed variables and their values, the most tedious part
of the process was done mechanically. 

In the remainder of this essay, we discuss the process of creating
a variable key template, revising it, and putting it to use. 

\section{Four Simple Steps}

The variable key process has four steps. First, inspect an R data.frame
object and create a key template file. The key template summarizes
the existing state of the variables and creates ``placeholders''
where we might like to specify revisions. Second, edit the key template
file in a spreadsheet or other program that can work with comma separate
variables. Change the names, values, and designate other recodes (which
we will describe next). Third, import the revised key into R. Fourth,
apply the key to the data to generate a new, improved data frame.
Then run some diagnostic routines.

If all goes well, we should end up with a new data frame in which
\begin{enumerate}
\item The columns are renamed in accordance with the instructions of the
principal investigator (or supervisor).
\item The values of all variables have been recoded according to the instructions
of the principal investigator (or supervisor).
\end{enumerate}
Diagnostic tables are reported to clearly demonstrate the effect of
each coding change, mapping out the difference between the input and
the output variables. 

For purposes of illustration, we have create an example data frame
with various types of variables. This data frame, \code{mydf}, has
most of the challenges that we see in actual projects. It has integer
variables that need to be reorganized and turned into character or
factor variables. It has character variables that might become integers
or factors. 

<<eval=T,include=T>>=
set.seed(234234)
N <- 200
mydf <- data.frame(
    x5 = rnorm(N),
    x4 = rpois(N, lambda = 3),
    x3 = ordered(sample(c("lo", "med", "hi"), size = N, replace=TRUE),
            levels = c("med", "lo", "hi")),
    x2 = letters[sample(c(1:4,6), 200, replace = TRUE)],
    x1 = factor(sample(c("cindy", "jan", "marcia"), 200,
            replace = TRUE)),
    x7 = ordered(letters[sample(c(1:4,6), 200, replace = TRUE)]),
    x6 = sample(c(1:5), 200, replace = TRUE),
            stringsAsFactors = FALSE)
mydf$x4[sample(1:N, 10)] <- 999
mydf$x5[sample(1:N, 10)] <- -999
@

\subsection{Step 1. Create a Key Template}

The function \code{keyTemplate} scans a data frame and generates
a new key template. The key has 8 pieces of information about each
variable:
\begin{enumerate}
\item name\_old
\item name\_new
\item class\_old
\item class\_new
\item value\_old
\item value\_new
\item missings
\item recodes
\end{enumerate}
The first 6 elements will be filled in with the old values equal to
the new values. 

At the current time, there are two formats for the key template, ``long''
and ``wide''. These names are used in the same sense in which those
terms are used in R's reshape function. The two key formats are intended
to be interchangeable in functionality. Some users may prefer to edit
variable information in one method and the re-importation of the key's
information should deal gracefully with either type of variable key. 

A wide format key can be produced with a call to the \code{keyTemplate}
function like so:

<<eval=F>>=
key <- keyTemplate(mydf, file = "key_wide.csv")
@

\noindent That will produce a ``wide'' key (the default). On the
other hand, one can ask for a long format key by including the long
argument:

<<eval=F>>=
key <- keyTemplate(mydf, long = TRUE, file = "key_long.csv")
@

\noindent Because the file argument is supplied, a file is created
at the same time. At the current time, names ending in ``\code{\noindent .csv}'',
``\code{\noindent .xlsx}'', and ``\code{\noindent .rds}'' are
allowed (for creating comma separated variables, Excel spreadsheets,
and R serialization data structures). Some users may prefer to save
the key in other formats, but that will not be handled by \code{\noindent keyTemplate}
automatically. One should save the key object in a separate step in
another format is needed.

The \code{keyTemplate} function's argument \code{long} can be set
as \code{TRUE} or \code{FALSE}. If \code{FALSE}, the key template
will be in the wide. The essence of the difference is that the wide
format puts all of the required information into a one-row-per-variable
format, while the long version creates one-row-per-value. The difference
is most apparent if we begin with the example \code{mydf}.

A LaTeX rendition of the data.frame object that holds a wide key template
is demonstrated in Table \ref{tab:The-Wide-Key}. It is called a wide
key because the recoding information is tightly packed into \code{value\_old}
and \code{value\_new}. The key includes more or less obvious columns
for the old and new variable names, their classes, and values of the
variables. That key results from the following code. 

<<key0, include=F>>=
library(kutils)
library(xtable)
@

<<key10>>=
keywide <- keyTemplate(mydf, max.levels = 5)
@

\noindent The \code{\noindent max.levels} parameter defaults to 15,
so that an integer variable with less than 15 values will have each
value displayed. The display of that variable key was too wide for
the page in this essay, so we reduced the number of values. When the
observed number of scores is above \code{\noindent max.levels}, the
key does not try to list the individual values (compare the treatment
of variables \code{\noindent x4} and \code{\noindent x6}). 

A long key template is displayed in Table \ref{tab:Long-Key}. That
key is produced as follows.

<<key30>>=
keylong <- keyTemplate(mydf, long = TRUE, max.levels = 5)
@

\begin{table}[h]
\caption{The Wide Key Template\label{tab:The-Wide-Key}}

\def\Sweavesize{\tiny}
<<key20,echo=FALSE,results=tex>>=
print(xtable(keywide), include.rownames = FALSE, size = "small", floating = FALSE )
@
\end{table}

\begin{table}
\caption{The Long Key Template\label{tab:Long-Key}}

\def\Sweavesize{\tiny}
<<key40,echo=FALSE,results=tex>>=
print(xtable(keylong), include.rownames = FALSE, size = "small", floating = FALSE)
@
\end{table}

It is necessary to treat categorical and numeric data differently.
If a column includes floating point numbers (temperatures, dollar
values, etc), then we would not plan for a research mission that wants
to recode individual values one-by-one. However, if a column includes
integers, then the project may intend to treat them as discrete values
(1 = male, 2 = female). They may also be numeric, however, and we
don't expect to recode individual values (age, IQ score). A numeric
variable may need to be recoded, say by the elimination of missing
values or by the application of a transformation (logarithm, etc).
We handle those recodes from a different point of view, with the \code{missings}
and \code{recodes} columns in the variable key. 

The information for \code{values\_old} and \code{values\_new} is
much more elaborate for discrete variables. For discrete variables
(factors, characters, integers), researchers do want to freely reassign
and regroup the observed values. If the observed number of unique
scores is smaller than max.levels, then the key will enumerate them.
If more values are observed, the key will not enumerate them. If a
researchers feels this is incorrect, then the key can be edited to
enumerate and change the values (see below).

The same issue arises with character variables. A column coded as
``male'' or ``female'' falls into a different frame of mind than
a character variable which represents a survey respondent's name or
ID number. We want the key to include all of the values of the former
type of character, but it probably should not enumerate all of values
of the other type. The max.levels parameter is just a way of guessing
how many unique levels is ``too many'' for an enumeration.

Despite the possibility that a factor (or ordered) variable may have
many values, we believe that all of the levels of those variables
should be usually be included in the key. If a variable is declared
as a factor, it means the researcher has assigned meaning to the various
observed values and we are reluctant to ignore them.

Some users have asked ``should we use the wide key or the long key?''
This is simply a matter of taste. In a project that has variables
with many unique observed values, the wide format may become hard
to manage. The long format eliminates any ambiguity about the old
value and the new value. The disadvantage of the long format is that
it is somewhat verbose, with repeated values in the name and class
values.

\subsection{Step 2. Edit the variable key}

The variable key that is generated by \code{keyTemplate} should,
without editing, be sufficient to re-import the data and reproduce
exactly the same data frame. As a result, it is not necessary to make
extensive changes in a key. One may simply intend to rename all of
the columns, for example, by editing \code{name\_new}. The supervisor
and principal investigator can change just a few variable names or
values. In a large project, there may be quite a bit of work involved. 

Because editing the key can be a rather involved process, we will
wait to discuss the details until section 

\subsection{Step 3. keyImport}

Once any desired changes to variables have been entered into the variable
key, the file needs to be imported back into R. First, the csv (\code{read.csv}),
xlsx (\code{openxlsx::read.xlsx}), or rds (\code{readRDS}) file
containing the edited key needs to be read into R. It is important
to specify \code{stringsAsFactor = FALSE} as an argument when reading
the key into R. Next the key is provided to the \code{keyImport}
function in \code{kutils}. The \code{keyImport} function is set
to read short keys by default, providing the argument \code{long = TRUE}
will switch to a long key. The \code{keyImport} function always returns
a list with information about how each variable is to be recoded.
The structure of the list will be the same with a long or short key
being provided. Inspecting the key list will show that each item contains
the information provided in a single row of a short key. The key list
has a fixed format so that the process of using the key list to manipulate
the data is not influenced by what key format was used. We do not
suggest attempting to create a key list manually. See the code below
for a basic example of how a key file is read into R and then provided
to \code{keyImport}. 

\noindent\begin{minipage}[t]{1\columnwidth}%
\inputencoding{latin9}\begin{lstlisting}
mydf.key <- read.csv("mydf.key.csv", stringsAsFactor = FALSE) 
mydf.keylist <- keyImport(mydf.key, long = FALSE)
\end{lstlisting}
\inputencoding{utf8}%
\end{minipage}

\subsection{Step 4. Apply the imported key to the data}

The final step is to apply the key to the data frame that needs variables
recoded. The recoded data frame is obtained by assigning a name to
the output of the \code{kutils} function \code{keyApply}. The \code{keyApply}
function takes the name of the data frame to be recoded and the key
list created in Step 3 to produce a new data frame with the desired
recodings. See the code below for a basic example of how an imported
key is applied to a data frame. 

\noindent\begin{minipage}[t]{1\columnwidth}%
\inputencoding{latin9}\begin{lstlisting}
keyed.df <- keyApply(mydf, mydf.keylist)
\end{lstlisting}
\inputencoding{utf8}%
\end{minipage}

\section{Editing the variable key\label{sec:Editing-the-key}}

\subsection{Factor, ordered, and character variables}

The recoding of discrete variables is a fairly obvious chore. For
each old value, a new value may be specified. 

In the case of character variable input, we allow for various output
possibilities. The value of \code{class\_new} will be \code{character},
\code{factor}, \code{ordered}, or \code{integer}. It is necessary
to match up the old values and new values, of course, but there is
nothing complicated about it. In the \code{mydf} variable key, we
have variable \code{x2} which is coded \code{a} through \code{f}.
Examples of key elements that might change that into a new character,
factor, or integer variable are illustrated in Table \ref{tab:Change-Type-Example1}.
Here we show the middle section of the revised key in which we have
spawned 3 new variants of x2, each with its own name

\begin{table}[H]
\caption{Change Class, Example 1\label{tab:Change-Type-Example1}}

\begin{tabular}{ccccc}
\hline 
name\_new & class\_old & class\_new & value\_old & value\_new\tabularnewline
\hline 
x2.char & character & character & a|b|c|d|f & Excellent|Proficient|Good|Fair|Poor\tabularnewline
x2.fac & character & factor & a|b|c|d|f & Excellent|Proficient|Good|Fair|Poor\tabularnewline
x2.gpa & character & integer & a|b|c|d|f & 4|3|2|1|0\tabularnewline
\hline 
\end{tabular}
\end{table}

In line one of Table \ref{tab:Change-Type-Example1}, the class \code{character}
remains the same. That line will produce a new character variable
with embellished values. Line two demonstrates how to create an R
factor variable. We change the class\_new to factor. It is also possible
to convert the character input into integer values, as we see in line
3.

Similarly, it is obvious to see how an integer input can be converted
into either an integer, character, or factor variable by employing
any of the rows seen in Table \ref{tab:Change-Type-Example2}.

\begin{table}[H]
\caption{Change Class Example 2\label{tab:Change-Type-Example2}}

\begin{tabular}{ccccc}
\hline 
name\_new & class\_old & class\_new & value\_old & value\_new\tabularnewline
\hline 
x6.i100 & integer & integer & 1|2|3|4|5 & 100|200|300|400|500\tabularnewline
x6.c & integer & character & 1|2|3|4|5 & Austin|Denver|Nashville|Provo|Miami\tabularnewline
x6.f & integer & factor & 1|2|3|4|5 & F|D|C|B|A\tabularnewline
\hline 
\end{tabular}
\end{table}

If a variable's class\_old is ordered, and we simply want to relabel
the existing levels, the work is also easy (see Table \ref{tab:Change-Type-Example3}).

\begin{table}[H]
\caption{Change Class, Example 3\label{tab:Change-Type-Example3}}

\begin{tabular}{ccccc}
\hline 
name\_new & class\_old & class\_new & value\_old & value\_new\tabularnewline
\hline 
x7.grades & ordered & ordered & f<d<c<b<a & F<D<C<B<A\tabularnewline
x7.passfail & ordered & ordered & f<d<c<b<a & Fail<Fail<Pass<Pass<Pass\tabularnewline
x7.gpa & ordered & integer & f<d<c<b<a & 0|1|2|3|4\tabularnewline
\hline 
\end{tabular}
\end{table}

The second row in Table \ref{tab:Change-Type-Example3} shows that
factor levels can be ``combined'' by assigning the same character
string to several ``<'' separated values. 

Working with ordered variables, whether as input or output, becomes
more complicated if the existing data is not ordered in the way we
want. In the \code{mydf} example, the variable \code{mydf\$x3} was
coded as an ordered variable with levels (``med'', ``lo'', ``high'').
That might have been one person's idea of a joke, so we need to rearrange
these as (``lo'', ``med'', ``high''). If the original ordering
of the values is not consistent with the desired ordering of the new
ordered factor, then we need notation that allows researchers to achieve
two purposes. First, the values must be re-leveled. Second, allow
for the possibility that the new values must be relabeled as well.
We'd rather not proliferate new columns in the variable key or create
some confusing new notation.

Reordering variable levels requires us to do something that seems
dangerous. We need to edit the \code{value\_old} to correct the ordering
of the levels \emph{as they are currently labeled}. This is the only
time where we suggest that users edit the \code{value\_old} column.
In \code{value\_new}, supply new labels in the in the correct order
to parallel the newly edited \code{value\_old} column (see Table
\ref{tab:Reorder-Values}).

\begin{table}[H]
\caption{Reorder Values, Example 1\label{tab:Reorder-Values}}

\begin{tabular}{ccccc}
\hline 
 & class\_old & class\_new & value\_old & value\_new\tabularnewline
\hline 
x3.lo2hi & ordered & ordered & low<med<hi & low<medium<high\tabularnewline
x3.passfail & ordered & ordered & low<med<hi & low<pass<pass\tabularnewline
\hline 
\end{tabular}
\end{table}

The key importer will check that all ``duplicated levels'' are adjacent
with one another, so that the values above low are grouped together.

In the long key format, the equivalent information would be conveyed
by altering the ordering of the rows. For example, it is necessary
to re-order the rows to indicate the lo is lower than med, and then
for the new values we put in the desired names (see Table \ref{tab:Reorder-Values-Example2}).

\begin{table}[H]
\caption{Reorder Values, Example 2\label{tab:Reorder-Values-Example2}}

\begin{tabular}{llllllll}
\toprule
name\_old & name\_new & class\_old & class\_new & value\_old & value\_new & missings & recodes \\
\midrule
x3 & x3lo2hi & ordered & ordered & lo & low &  &  \\
x3 & x3lo2hi & ordered & ordered & med & medium &  &  \\
x3 & x3lo2hi & ordered & ordered & hi & high &  &  \\
x3 & x3.passfail & ordered & ordered & low & low & & \\
x3 & x3.passfail & ordered & ordered & medium & pass & & \\
x3 & x3.passfail & ordered & ordered & high & pass & & \\
\bottomrule
\end{tabular}
\end{table}

The R symbol for missing values, NA, can be used in place of any new
value to indicate that cases with a particular score should be treated
as missing. Sometimes there is confusion when data is passed in and
out of CSV or XLSX format, because a character variable might have
a legal value ``NA'' and it may also be necessary to assign the
R missing value of NA. 

TODO: fix this, describe the output key ``mydf.key.csv'' and get
EXCEL discussion on how to add quoted elements inside strings. Need
to write out what Excel does to a string like ``cindy|bobby|''NA''|'',
figure out why the key currently exports one big string ``bobby|cindy|marcia''
when perhaps instead it should export ``''bobby''|''cindy''|''marcia'').

\subsubsection{About numeric variables}

In the process that creates the variable key template, we attempt
to separate the variables with meaningfully discrete values–ones that
we recode by reassignment of one-by-one values–from numeric variables
that we think of differently. The non-discrete variables are included
as one row in a variable key (whether wide or long) and the main elements
of interest for these variables are the columns labeled \code{missings}
and \code{recodes}. 

The key specification of missing values for various types of variables
is spelled out in detail for the help page of the \code{assignMissing}
function in \code{kutils}. For numeric variables, there are only
three types of statements allowed in the \code{missings} column.
Legal values must must begin with the characters ``<'', ``>'',
or ``c''. The first two indicate that observed scores less than,
or greater than, the value which follows are treated as missing. The
symbols ``<='' and ``>='' are accepted in the obvious way. See
Table \ref{tab:Recode-Examples} for examples of possible \code{missings}
input. 

\begin{table}[H]
\caption{Missings Examples\label{tab:Recode-Examples}}

\begin{tabular}{|c|c|c|}
\hline 
missings & interpretation: NA will be assigned to  & example\tabularnewline
\hline 
> t & values greater than t & > 99\tabularnewline
>= t & values greater than or equal to t  & >=99\tabularnewline
<t & values less than t  & <0\tabularnewline
<=t & values less than or equal to t  & <=0\tabularnewline
c(a,b) & values equal to or greater than a and less than or equal to b  & c(-999,0)\tabularnewline
\hline 
\end{tabular}
\end{table}

The key specification for \code{recodes} is discussed in the help
page of the \code{assignRecode} function in \code{kutils}. The \code{recodes}
column takes R code and applies it to the desired variable. For example,
if one wanted to transform a variable by taking its square root, this
could be done by providing ``sqrt(x)'' in the \code{recodes} column.
Here ``x'' is simply a placeholder where the name of the variable
indicated in the \code{name\_new} column will be inserted when the
variable key is applied. 

\begin{table}[H]
\caption{Recoding Integer and Numeric Variables}

{\footnotesize

\begin{tabular}{lllllllll}
  \toprule
name\_old & name\_new & class\_old & class\_new & value\_old & value\_new & missings & recodes \\
  \midrule
x5 & x5 & numeric & numeric &  &  & <0 & log(x) \\
x4 & x4 & numeric & numeric &  &  & c(-999) & abs(x) \\
x6 & x6 & integer & integer & 1$|$2$|$3$|$4$|$5 & 1$|$2$|$3$|$4$|$5 & c(-9) & \\
   \bottomrule
\end{tabular}

}
\end{table}


\subsection*{Class concerns}

Two elements in this key that we have not already mentioned are the
columns named class\_old and class\_new. These were introduced to
facilitate two chores. First, we might edit the values of the class\_old
variable, and then use those classes to re-import the data and reassign
the variables in a desired way. Another scenario might be that a client
provides a new data frame which is allegedly equivalent to a previous
set. The values in class\_old and value\_old might give us a first
step to verifying their claim that the new data is actually equivalent.
Second, the class\_new column allows us to indicate, for example,
that a variable currently coded as 1 for males and 2 for female should
become an R factor variable with an indicated set of levels.

As described in the R help page for the function \code{as.numeric},
there are some confusing aspects in the treatment of integers and
floating point values in R. The R function \code{is.numeric} will
return TRUE if the variable under consideration is an integer or a
floating point variable, although as.numeric returns a floating-point
(double) variable. It is possible for users to declare variables as
integers, however, and so the two types of numeric variables are not
necessarily indistinguishable. To disambiguate, the keyTemplate function
marks class\_old for a known integer variable as ``integer'', while
the more ambiguous class\_old value ``numeric'' is used for variables
that are truly double-precision floating point numbers or integer
variables that have not were not declared as integers when the data
was imported.

\section{Discussion}

When a project has a small budget, we invite the principal investigator
to economize on the expenses by filling out the variable key's \code{name\_new},
\code{class\_new}, and \code{value\_new} columns. There are several
benefits in inviting the clients (or PIs) to be directly involved
in filling in the variable key. Most importantly, they are allowed
to name the variables in any way that is meaningful to them. When
statistical results are obtained, it is never necessary for them to
ask, ``what did you mean by this variable \code{occupation}?''
There are other benefits, however. By making the principal investigator
aware of the values that are actually observed, and by offering the
opportunity to specify how they ought to be recoded, a substantial
element of administrative slippage is ameliorated. The variable key
will specify exactly how categories are to be re-mapped, there is
much less danger of an accident buried in thousands of lines of recodes.

It often happens that the raw data to be imported is provided by one
of the national data centers. The variables are given exciting, meaningful
column names like V34342a. It appears to be almost certain that research
assistants will conclude that these names are not meaningful, so they
create names that are more meaningful to them, such as \emph{gender},
\emph{sex}, \emph{male}, \emph{female}, or whatnot. The research assistants
disappear into a haze of code and come out talking about the effect
of income, gender, and education on educational achievement, and the
principal investigator has to say, ``which of those variables is
income, again?'' and ``what's the coding on education?'' A very
exciting conversation then follows as one of the research assistant
realizes that V34342b is the one that should have been used for gender,
while V34342a indicates if the respondent ever visited Eastern Europe.

Although some bright people don't know R, it appears they are all
fluent in spread sheet.

\noindent\begin{minipage}[t]{1\columnwidth}%
Variable Key Editing Guidelines
\begin{enumerate}
\item Omit a variable: delete its row(s) from the (long)key.
\item The ``class\_new'' value must be one of the following

\begin{enumerate}
\item discrete variable types:

\begin{description}
\item [{integer}]~
\item [{factor}]~
\item [{ordered}]~
\item [{logical}]~
\item [{character}]~
\item [{Date}]~
\end{description}
\item floating-point numeric variable types:

\begin{description}
\item [{numeric}]~
\end{description}
\end{enumerate}
\item Creating new variables. Each input variable may be recoded in several
different ways, assigning a name\_new value unique for each. 
\item Assigning new values. 

\begin{enumerate}
\item discrete variable types.

\begin{enumerate}
\item New ``value\_old'' elements can be inserted in anticipation of new
data sets with previously unobserved values.
\item To assign new values to any of the discrete variable types, set values
in ``value\_new''. It is important that the values can be coerced
by R to match the value of ``class\_new''. That is to say, if ``class\_new''
is a ``integer'', then ``value\_new'' should be an integer.
\end{enumerate}
\item numeric variable types. 

\begin{enumerate}
\item Because floating point numbers do not allow comparison with ``=='',
it is not allowed to use ``value\_old'' and ``value\_new'' pairs
for these variables. It is necessary to write statements in the recode
column of the variable key.
\end{enumerate}
\end{enumerate}
\item Assign missings:

\begin{enumerate}
\item discrete variables: several options, we should settle on one suggestion

\begin{enumerate}
\item insert ``NA'' in value\_new column
\item delete the value\_old entry (not the best way, maybe don't mention
it)
\item list a vector of missing values in the recode column. This vector
applies to data as it was imported, before applying the value\_old
to value\_new transition. PROBLEM: if input data's class does not
match class\_old, there may be a problem.
\end{enumerate}
\item numeric variables
\end{enumerate}
\end{enumerate}
%
\end{minipage}

\bibliographystyle{chicago}
\bibliography{kutils}

\end{document}
